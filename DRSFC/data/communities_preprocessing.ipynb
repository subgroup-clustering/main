{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be49f6f1",
   "metadata": {},
   "source": [
    "Create single version with 18 sensitive attributes:\n",
    "- communities(18): 18 binarized sensitive attributes\n",
    "\n",
    "Sensitive attributes (paper18 preset):\n",
    "- Race percentages (4): racepctwhite, racepctblack, racepctasian, racepcthisp\n",
    "- Per-capita income by race (6): whitepercap, blackpercap, indianpercap, asianpercap, otherpercap, hisppercap\n",
    "- Language/immigration (8): pctnotspeakenglwell, pctforeignborn, pctimmigrecent, pctimmigrec5, pctimmigrec8, pctimmigrec10, pctrecentimmig, pctrecimmig5\n",
    "\n",
    "**filtering**: Remove rows with missing values in sensitive attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268eae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb756b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1994, 128)\n",
      "Columns (first 10): ['attributecharacteristics', 'state', 'county', 'community', 'fold', 'population', 'householdsize', 'racepctblack', 'racepctwhite', 'racepctasian']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributecharacteristics</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racepctwhite</th>\n",
       "      <th>racepctasian</th>\n",
       "      <th>...</th>\n",
       "      <th>landarea</th>\n",
       "      <th>popdens</th>\n",
       "      <th>pctusepubtrans</th>\n",
       "      <th>policcars</th>\n",
       "      <th>policoperbudg</th>\n",
       "      <th>lemaspctpoliconpatr</th>\n",
       "      <th>lemasgangunitdeploy</th>\n",
       "      <th>lemaspctofficdrugun</th>\n",
       "      <th>policbudgperpop</th>\n",
       "      <th>violentcrimesperpop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81440.0</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attributecharacteristics  state   county            community  fold  \\\n",
       "0                         8    NaN      NaN         Lakewoodcity     1   \n",
       "1                        53    NaN      NaN          Tukwilacity     1   \n",
       "2                        24    NaN      NaN         Aberdeentown     1   \n",
       "3                        34    5.0  81440.0  Willingborotownship     1   \n",
       "4                        42   95.0   6096.0    Bethlehemtownship     1   \n",
       "\n",
       "   population  householdsize  racepctblack  racepctwhite  racepctasian  ...  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12  ...   \n",
       "1        0.00           0.16          0.12          0.74          0.45  ...   \n",
       "2        0.00           0.42          0.49          0.56          0.17  ...   \n",
       "3        0.04           0.77          1.00          0.08          0.12  ...   \n",
       "4        0.01           0.55          0.02          0.95          0.09  ...   \n",
       "\n",
       "   landarea  popdens  pctusepubtrans  policcars  policoperbudg  \\\n",
       "0      0.12     0.26            0.20       0.06           0.04   \n",
       "1      0.02     0.12            0.45        NaN            NaN   \n",
       "2      0.01     0.21            0.02        NaN            NaN   \n",
       "3      0.02     0.39            0.28        NaN            NaN   \n",
       "4      0.04     0.09            0.02        NaN            NaN   \n",
       "\n",
       "   lemaspctpoliconpatr  lemasgangunitdeploy  lemaspctofficdrugun  \\\n",
       "0                  0.9                  0.5                 0.32   \n",
       "1                  NaN                  NaN                 0.00   \n",
       "2                  NaN                  NaN                 0.00   \n",
       "3                  NaN                  NaN                 0.00   \n",
       "4                  NaN                  NaN                 0.00   \n",
       "\n",
       "   policbudgperpop  violentcrimesperpop  \n",
       "0             0.14                 0.20  \n",
       "1              NaN                 0.67  \n",
       "2              NaN                 0.43  \n",
       "3              NaN                 0.12  \n",
       "4              NaN                 0.03  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_colname(name):\n",
    "    \"\"\"Normalize column name: lowercase, remove non-alphanumeric\"\"\"\n",
    "    name = name.lower().strip().replace('\\t', ' ')\n",
    "    name = re.sub(r'[^a-z0-9_]', '', name)\n",
    "    return name\n",
    "\n",
    "def parse_names_file(names_path, ncols):\n",
    "    \"\"\"Parse .names file to get column names\"\"\"\n",
    "    if not names_path.exists():\n",
    "        return []\n",
    "    allowed = ('continuous', 'integer', 'real', 'numeric', 'binary', 'nominal')\n",
    "    cand = []\n",
    "    with open(names_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line or line.startswith('|') or line.startswith('#'):\n",
    "                continue\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            left, right = line.split(':', 1)\n",
    "            if any(tok in right.lower() for tok in allowed):\n",
    "                name = normalize_colname(left)\n",
    "                if name:\n",
    "                    cand.append(name)\n",
    "    if len(cand) == ncols:\n",
    "        return cand\n",
    "    if len(cand) > ncols:\n",
    "        return cand[-ncols:]\n",
    "    return []\n",
    "\n",
    "# Load Communities data\n",
    "raw_dir = Path('raw/communities')\n",
    "data_path = raw_dir / 'communities.data'\n",
    "names_path = raw_dir / 'communities.names'\n",
    "\n",
    "df = pd.read_csv(data_path, header=None, na_values=['?'], skipinitialspace=True)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "# Parse column names from .names file\n",
    "header = parse_names_file(names_path, df.shape[1])\n",
    "if header:\n",
    "    df.columns = header\n",
    "else:\n",
    "    df.columns = [f'col{i}' for i in range(df.shape[1])]\n",
    "    print(\"[WARN] Failed to parse names, using generic column names\")\n",
    "\n",
    "print(f\"Columns (first 10): {list(df.columns[:10])}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca53a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing sensitive attrs: 18/18\n",
      "\n",
      "Rows with complete sensitive attrs: 1993/1994\n"
     ]
    }
   ],
   "source": [
    "# Define sensitive attributes\n",
    "sens_attrs_ordered = [\n",
    "    # Race percentages (4)\n",
    "    'racepctwhite', 'racepctblack', 'racepctasian', 'racepcthisp',\n",
    "    # Per-capita income by race (6)\n",
    "    'whitepercap', 'blackpercap', 'indianpercap', 'asianpercap', 'otherpercap', 'hisppercap',\n",
    "    # Language/immigration related (8)\n",
    "    'pctnotspeakenglwell', 'pctforeignborn',\n",
    "    'pctimmigrecent', 'pctimmigrec5', 'pctimmigrec8', 'pctimmigrec10',\n",
    "    'pctrecentimmig', 'pctrecimmig5',\n",
    "]\n",
    "\n",
    "# Check which columns exist\n",
    "existing_sens = [c for c in sens_attrs_ordered if c in df.columns]\n",
    "missing_sens = [c for c in sens_attrs_ordered if c not in df.columns]\n",
    "print(f\"Existing sensitive attrs: {len(existing_sens)}/{len(sens_attrs_ordered)}\")\n",
    "if missing_sens:\n",
    "    print(f\"Missing: {missing_sens}\")\n",
    "\n",
    "# Filter: remove rows with missing values in sensitive attributes\n",
    "sens_df = df[existing_sens].copy()\n",
    "mask_valid = sens_df.notna().all(axis=1)\n",
    "print(f\"\\nRows with complete sensitive attrs: {mask_valid.sum()}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dd4a8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered shape: (1993, 128)\n",
      "S shape: (1993, 18)\n",
      "\n",
      "Sensitive attribute value counts:\n",
      "  racepctwhite: {0: 1031, 1: 962}\n",
      "  racepctblack: {0: 1024, 1: 969}\n",
      "  racepctasian: {0: 997, 1: 996}\n",
      "  racepcthisp: {0: 1040, 1: 953}\n",
      "  whitepercap: {0: 1016, 1: 977}\n"
     ]
    }
   ],
   "source": [
    "# Apply filter\n",
    "df_filtered = df.loc[mask_valid].reset_index(drop=True)\n",
    "print(f\"Filtered shape: {df_filtered.shape}\")\n",
    "\n",
    "def binarize_quantile(series, q=0.5):\n",
    "    \"\"\"Binarize by quantile threshold\"\"\"\n",
    "    v = pd.to_numeric(series, errors='coerce')\n",
    "    finite = v.dropna()\n",
    "    if finite.empty:\n",
    "        return pd.Series(0, index=v.index, dtype=int)\n",
    "    \n",
    "    thr = finite.quantile(q)\n",
    "    result = (v > thr).astype(int)\n",
    "    return result\n",
    "\n",
    "# Build sensitive attribute matrix (binarized)\n",
    "S_df = pd.DataFrame()\n",
    "for attr in existing_sens:\n",
    "    S_df[attr] = binarize_quantile(df_filtered[attr], q=0.5)\n",
    "\n",
    "print(f\"S shape: {S_df.shape}\")\n",
    "print(\"\\nSensitive attribute value counts:\")\n",
    "for attr in S_df.columns[:5]:  # Show first 5 only\n",
    "    counts = S_df[attr].value_counts().to_dict()\n",
    "    print(f\"  {attr}: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c230ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column: violentcrimesperpop\n",
      "Label distribution: [1410  583]\n",
      "Feature columns: 105\n",
      "\n",
      "X shape: (1993, 105)\n",
      "y shape: (1993,)\n",
      "S shape: (1993, 18)\n",
      "\n",
      "X shape: (1993, 105)\n",
      "y shape: (1993,)\n",
      "S shape: (1993, 18)\n"
     ]
    }
   ],
   "source": [
    "# Define label column (ViolentCrimesPerPop)\n",
    "target_col = 'violentcrimesperpop' if 'violentcrimesperpop' in df_filtered.columns else df_filtered.columns[-1]\n",
    "print(f\"Target column: {target_col}\")\n",
    "\n",
    "# Binarize label (top 30% = 1, as in paper)\n",
    "y = binarize_quantile(df_filtered[target_col], q=0.7).values\n",
    "print(f\"Label distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Feature columns (exclude target, sensitive attrs, and non-predictive cols)\n",
    "non_feature_cols = (\n",
    "    [target_col, 'state', 'county', 'community', 'communityname', 'fold']\n",
    "    + list(existing_sens)\n",
    ")\n",
    "feature_cols = [c for c in df_filtered.columns if c not in non_feature_cols]\n",
    "print(f\"Feature columns: {len(feature_cols)}\")\n",
    "\n",
    "# Build feature matrix\n",
    "X_raw = df_filtered[feature_cols].copy()\n",
    "X_raw = X_raw.apply(pd.to_numeric, errors='coerce')\n",
    "X_raw = X_raw.fillna(X_raw.median())\n",
    "X_raw = X_raw.fillna(0)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_raw)\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"S shape: {S_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e496f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved communities(18): X(1993, 105), y(1993,), S(1993, 18)\n",
      "  Sensitive attrs: ['racepctwhite', 'racepctblack', 'racepctasian', 'racepcthisp', 'whitepercap', 'blackpercap', 'indianpercap', 'asianpercap', 'otherpercap', 'hisppercap', 'pctnotspeakenglwell', 'pctforeignborn', 'pctimmigrecent', 'pctimmigrec5', 'pctimmigrec8', 'pctimmigrec10', 'pctrecentimmig', 'pctrecimmig5']\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Save communities(18): q=18 sensitive attributes\n",
    "save_dir = Path('.') / 'communities(18)'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "S = S_df.values\n",
    "\n",
    "np.save(save_dir / 'X.npy', X)\n",
    "np.save(save_dir / 'y.npy', y)\n",
    "np.save(save_dir / 'S.npy', S)\n",
    "\n",
    "print(f\"Saved communities(18): X{X.shape}, y{y.shape}, S{S.shape}\")\n",
    "print(f\"  Sensitive attrs: {list(S_df.columns)}\")\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
